lib/rhashtable.o
__rhashtable_walk_find_next -> (rht_bucket_nested)
bucket_table_alloc -> (get_random_u32, kmalloc_trace, kfree, kvmalloc_node)
bucket_table_free_rcu -> (nested_table_free, kfree, kvfree)
nested_table_free -> (kfree, nested_table_free)
rhashtable_destroy -> (rhashtable_free_and_destroy)
rhashtable_free_and_destroy -> (mutex_lock, nested_table_free, mutex_unlock, __SCT__cond_resched, kvfree, kfree, cancel_work_sync)
rhashtable_init -> (__mutex_init, bucket_table_alloc, kvmalloc_node, get_random_u32, rht_deferred_worker, rhashtable_jhash2, jhash)
rhashtable_insert_slow -> (bcmp, nested_table_free, bucket_table_alloc, queue_work_on, __rcu_read_lock, kvfree, rht_bucket_nested_insert, __rcu_read_unlock, kfree)
rhashtable_rehash_alloc -> (nested_table_free, kvmalloc_node, get_random_u32, kvfree, kfree)
rhashtable_walk_enter -> (_raw_spin_lock, _raw_spin_unlock)
rhashtable_walk_exit -> (_raw_spin_lock, _raw_spin_unlock)
rhashtable_walk_next -> (__rhashtable_walk_find_next)
rhashtable_walk_peek -> (__rhashtable_walk_find_next)
rhashtable_walk_start_check -> (rht_bucket_nested, _raw_spin_lock, __rcu_read_lock, _raw_spin_unlock)
rhashtable_walk_stop -> (__rcu_read_unlock, _raw_spin_lock, bucket_table_free_rcu, _raw_spin_unlock)
rhltable_init -> (rhashtable_init)
rht_bucket_nested_insert -> (kmalloc_trace, kfree)
rht_deferred_worker -> (mutex_lock, _raw_spin_unlock, mutex_unlock, _raw_spin_lock, queue_work_on, bucket_table_free_rcu, __SCT__cond_resched, rhashtable_rehash_alloc, call_rcu)
