mm/mlock.o
__do_sys_munlockall -> (__mmap_lock_do_trace_released, __SCT__tp_func_mmap_lock_acquire_returned, up_write, trace_mmap_lock_reg, __traceiter_mmap_lock_start_locking, __probestub_mmap_lock_released, down_write_killable, trace_mmap_lock_unreg, __traceiter_mmap_lock_released, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, apply_mlockall_flags, __mmap_lock_do_trace_start_locking)
__ia32_sys_mlock -> (do_mlock)
__ia32_sys_mlock2 -> (do_mlock)
__ia32_sys_mlockall -> (__se_sys_mlockall)
__ia32_sys_munlock -> (__se_sys_munlock)
__se_sys_mlockall -> (trace_mmap_lock_unreg, __mmap_lock_do_trace_start_locking, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, capable, __SCT__tp_func_mmap_lock_acquire_returned, __probestub_mmap_lock_released, down_write_killable, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __mmap_lock_do_trace_released, __mm_populate, up_write, trace_mmap_lock_reg, __traceiter_mmap_lock_start_locking, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned, apply_mlockall_flags)
__se_sys_munlock -> (__mmap_lock_do_trace_released, __SCT__tp_func_mmap_lock_acquire_returned, up_write, apply_vma_lock_flags, trace_mmap_lock_reg, __traceiter_mmap_lock_start_locking, __probestub_mmap_lock_released, down_write_killable, trace_mmap_lock_unreg, __traceiter_mmap_lock_released, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, __mmap_lock_do_trace_start_locking)
__x64_sys_mlock -> (do_mlock)
__x64_sys_mlock2 -> (do_mlock)
__x64_sys_mlockall -> (__se_sys_mlockall)
__x64_sys_munlock -> (__se_sys_munlock)
apply_mlockall_flags -> (mas_find, mlock_fixup, __SCT__cond_resched)
apply_vma_lock_flags -> (mas_prev, mas_walk, mlock_fixup, mas_find)
can_do_mlock -> (capable)
do_mlock -> (__mmap_lock_do_trace_acquire_returned, trace_mmap_lock_unreg, __mmap_lock_do_trace_start_locking, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, capable, __SCT__tp_func_mmap_lock_acquire_returned, apply_vma_lock_flags, __probestub_mmap_lock_released, down_write_killable, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __mmap_lock_do_trace_released, __mm_populate, up_write, trace_mmap_lock_reg, __traceiter_mmap_lock_start_locking, __SCT__tp_func_mmap_lock_released, mas_find)
mlock_drain_local -> (mlock_folio_batch)
mlock_drain_remote -> (mlock_folio_batch)
mlock_fixup -> (down_write, up_write, vma_is_secretmem, walk_page_range, mlock_pte_range, lru_add_drain, get_gate_vma, split_vma, vma_merge)
mlock_folio -> (mlock_folio_batch, mod_zone_page_state)
mlock_folio_batch -> (__mod_zone_page_state, release_pages, _raw_spin_lock_irq, folio_mapping, _raw_spin_unlock_irq, __rcu_read_lock, __mod_node_page_state, __rcu_read_unlock)
mlock_new_folio -> (mlock_folio_batch, mod_zone_page_state)
mlock_pte_range -> (__pte_offset_map_lock, _raw_spin_unlock, __SCT__cond_resched, vm_normal_folio, mlock_folio_batch, mlock_folio)
munlock_folio -> (mlock_folio_batch)
user_shm_lock -> (inc_rlimit_ucounts, dec_rlimit_ucounts, _raw_spin_unlock, _raw_spin_lock, get_ucounts, capable)
user_shm_unlock -> (_raw_spin_lock, put_ucounts, dec_rlimit_ucounts, _raw_spin_unlock)
