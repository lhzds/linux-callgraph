mm/mempolicy.o
__ia32_sys_get_mempolicy -> (__se_sys_get_mempolicy)
__ia32_sys_mbind -> (__se_sys_mbind)
__ia32_sys_migrate_pages -> (__se_sys_migrate_pages)
__ia32_sys_set_mempolicy -> (do_set_mempolicy, get_nodes)
__ia32_sys_set_mempolicy_home_node -> (__se_sys_set_mempolicy_home_node)
__mpol_dup -> (kmem_cache_alloc, _raw_spin_unlock, mpol_new_nodemask, _raw_spin_lock, mpol_rebind_nodemask, cpuset_mems_allowed, mpol_new_preferred, mpol_rebind_default, current_cpuset_is_being_rebound, mpol_rebind_preferred)
__mpol_put -> (kmem_cache_free)
__se_sys_get_mempolicy -> (_raw_spin_lock, __copy_overflow, trace_mmap_lock_unreg, _copy_to_user, __mmap_lock_do_trace_start_locking, __folio_put, _raw_spin_unlock, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, kmem_cache_free, compat_put_bitmap, __SCT__tp_func_mmap_lock_acquire_returned, down_read, __probestub_mmap_lock_released, mtree_load, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __mmap_lock_do_trace_released, get_user_pages_fast, trace_mmap_lock_reg, up_read, __traceiter_mmap_lock_start_locking, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned)
__se_sys_mbind -> (kmem_cache_alloc, __mmap_lock_do_trace_acquire_returned, get_nodes, putback_movable_pages, mpol_new_preferred, trace_mmap_lock_unreg, mbind_range, __mmap_lock_do_trace_start_locking, mpol_new_nodemask, queue_folios_hugetlb, migrate_pages, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, capable, kmem_cache_free, mpol_rebind_preferred, __SCT__tp_func_mmap_lock_acquire_returned, lru_cache_disable, queue_folios_pte_range, __probestub_mmap_lock_released, mpol_rebind_nodemask, walk_page_range, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, bitmap_fold, __mmap_lock_do_trace_released, down_write, up_write, bitmap_onto, trace_mmap_lock_reg, mas_prev, __traceiter_mmap_lock_start_locking, mpol_rebind_default, new_folio, __SCT__tp_func_mmap_lock_released, mas_find, queue_pages_test_walk)
__se_sys_migrate_pages -> (ptrace_may_access, refcount_warn_saturate, capable, find_task_by_vpid, mmput, get_nodes, cpuset_mems_allowed, do_migrate_pages, __rcu_read_lock, __put_task_struct, __rcu_read_unlock, security_task_movememory, get_task_mm)
__se_sys_set_mempolicy_home_node -> (__mmap_lock_do_trace_acquire_returned, __mpol_dup, trace_mmap_lock_unreg, mbind_range, __mmap_lock_do_trace_start_locking, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, kmem_cache_free, __SCT__tp_func_mmap_lock_acquire_returned, __probestub_mmap_lock_released, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __mmap_lock_do_trace_released, down_write, up_write, trace_mmap_lock_reg, mas_prev, __traceiter_mmap_lock_start_locking, __SCT__tp_func_mmap_lock_released, mas_find)
__x64_sys_get_mempolicy -> (__se_sys_get_mempolicy)
__x64_sys_mbind -> (__se_sys_mbind)
__x64_sys_migrate_pages -> (__se_sys_migrate_pages)
__x64_sys_set_mempolicy -> (do_set_mempolicy, get_nodes)
__x64_sys_set_mempolicy_home_node -> (__se_sys_set_mempolicy_home_node)
alloc_pages -> (cpuset_nodemask_valid_mems_allowed, __alloc_pages)
alloc_pages_bulk_array_mempolicy -> (__alloc_pages_bulk, cpuset_nodemask_valid_mems_allowed)
do_migrate_pages -> (putback_movable_pages, trace_mmap_lock_unreg, __mmap_lock_do_trace_start_locking, queue_folios_hugetlb, migrate_pages, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, __SCT__tp_func_mmap_lock_acquire_returned, down_read, lru_cache_disable, queue_folios_pte_range, __probestub_mmap_lock_released, walk_page_range, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, alloc_migration_target, find_vma, __mmap_lock_do_trace_released, bitmap_bitremap, trace_mmap_lock_reg, up_read, __traceiter_mmap_lock_start_locking, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned, queue_pages_test_walk)
do_set_mempolicy -> (kmem_cache_alloc, bitmap_onto, _raw_spin_unlock, mpol_new_nodemask, _raw_spin_lock, mpol_rebind_nodemask, mpol_new_preferred, mpol_rebind_default, bitmap_fold, kmem_cache_free, mpol_rebind_preferred)
folio_alloc -> (alloc_pages)
get_nodes -> (compat_get_bitmap, _copy_from_user)
huge_node -> (interleave_nid)
init_nodemask_of_mempolicy -> (_raw_spin_lock, _raw_spin_unlock)
mbind_range -> (split_vma, vma_replace_policy, vma_merge)
mempolicy_in_oom_domain -> (_raw_spin_lock, _raw_spin_unlock)
mempolicy_slab_node -> (__next_zones_zonelist)
mpol_free_shared_policy -> (rb_next, _raw_write_lock, rb_first, rb_erase, _raw_write_unlock, kmem_cache_free)
mpol_misplaced -> (kmem_cache_free, __next_zones_zonelist)
mpol_parse_str -> (kmem_cache_alloc, strcmp, match_string, bitmap_parselist, strchr)
mpol_put_task_policy -> (_raw_spin_lock, kmem_cache_free, _raw_spin_unlock)
mpol_rebind_mm -> (mpol_new_preferred, trace_mmap_lock_unreg, __mmap_lock_do_trace_start_locking, mpol_new_nodemask, __traceiter_mmap_lock_released, __traceiter_mmap_lock_acquire_returned, __probestub_mmap_lock_acquire_returned, mpol_rebind_preferred, __SCT__tp_func_mmap_lock_acquire_returned, __probestub_mmap_lock_released, mpol_rebind_nodemask, __SCT__tp_func_mmap_lock_start_locking, __probestub_mmap_lock_start_locking, __mmap_lock_do_trace_released, down_write, up_write, trace_mmap_lock_reg, __traceiter_mmap_lock_start_locking, mas_find, mpol_rebind_default, __SCT__tp_func_mmap_lock_released, __mmap_lock_do_trace_acquire_returned)
mpol_rebind_nodemask -> (bitmap_remap, bitmap_fold, bitmap_onto)
mpol_rebind_task -> (mpol_new_nodemask, mpol_rebind_nodemask, mpol_new_preferred, mpol_rebind_default, mpol_rebind_preferred)
mpol_set_shared_policy -> (kmem_cache_alloc, rb_insert_color, rb_next, _raw_write_lock, __mpol_dup, rb_prev, rb_erase, _raw_write_unlock, kmem_cache_free)
mpol_shared_policy_init -> (kmem_cache_alloc, bitmap_onto, _raw_spin_unlock, mpol_new_nodemask, _raw_spin_lock, mpol_rebind_nodemask, mpol_new_preferred, mpol_rebind_default, bitmap_fold, kmem_cache_free, mpol_rebind_preferred, mpol_set_shared_policy)
mpol_shared_policy_lookup -> (_raw_read_unlock, rb_prev, _raw_read_lock)
mpol_to_str -> (scnprintf, snprintf)
new_folio -> (folio_test_hugetlb, size_to_hstate, alloc_hugetlb_folio_vma, page_address_in_vma, mas_find, vma_alloc_folio)
numa_default_policy -> (_raw_spin_lock, kmem_cache_free, _raw_spin_unlock)
numa_map_to_online_node -> (__node_distance)
numa_policy_init -> (_printk, kmem_cache_create, do_set_mempolicy)
policy_nodemask -> (cpuset_nodemask_valid_mems_allowed)
queue_folios_hugetlb -> (_raw_spin_lock, isolate_hugetlb, hugetlb_pmd_shared, _raw_spin_unlock)
queue_folios_pte_range -> (__pte_offset_map_lock, _raw_spin_unlock, folio_isolate_lru, __SCT__cond_resched, mod_node_page_state, vm_normal_folio)
queue_pages_test_walk -> (find_vma)
vma_alloc_folio -> (__folio_alloc, kmem_cache_free, cpuset_nodemask_valid_mems_allowed, __alloc_pages)
vma_dup_policy -> (__mpol_dup)
vma_policy_mof -> (kmem_cache_free)
vma_replace_policy -> (kmem_cache_free, __mpol_dup)
