mm/rmap.o
__anon_vma_prepare -> (down_write, kmem_cache_alloc, __SCT__might_resched, up_write, _raw_spin_unlock, _raw_spin_lock, anon_vma_interval_tree_insert, find_mergeable_anon_vma, kmem_cache_free, __put_anon_vma)
__put_anon_vma -> (down_write, __SCT__might_resched, kmem_cache_free, up_write)
__traceiter_mm_migrate_pages -> (__probestub_mm_migrate_pages, __SCT__tp_func_mm_migrate_pages, __traceiter_mm_migrate_pages)
__traceiter_mm_migrate_pages_start -> (__probestub_mm_migrate_pages_start, __SCT__tp_func_mm_migrate_pages_start, __traceiter_mm_migrate_pages_start)
__traceiter_remove_migration_pte -> (__SCT__tp_func_remove_migration_pte, __traceiter_remove_migration_pte, __probestub_remove_migration_pte)
__traceiter_set_migration_pte -> (__probestub_set_migration_pte, __traceiter_set_migration_pte, __SCT__tp_func_set_migration_pte)
__traceiter_tlb_flush -> (__probestub_tlb_flush, __SCT__tp_func_tlb_flush, __traceiter_tlb_flush)
anon_vma_clone -> (down_write, kmem_cache_alloc, up_write, anon_vma_interval_tree_insert, unlink_anon_vmas)
anon_vma_ctor -> (__init_rwsem)
anon_vma_fork -> (down_write, kmem_cache_alloc, up_write, anon_vma_clone, anon_vma_interval_tree_insert, unlink_anon_vmas, __put_anon_vma)
anon_vma_init -> (anon_vma_ctor, kmem_cache_create)
flush_tlb_batched_pending -> (flush_tlb_mm_range)
folio_add_new_anon_rmap -> (linear_hugepage_index, __mod_node_page_state)
folio_get_anon_vma -> (__rcu_read_unlock, __rcu_read_lock, __put_anon_vma)
folio_lock_anon_vma_read -> (down_read, up_read, down_read_trylock, __rcu_read_lock, __rcu_read_unlock, __put_anon_vma)
folio_mkclean -> (folio_mapping, rmap_walk_file, page_mkclean_one, rmap_walk_anon, invalid_mkclean_vma)
folio_referenced -> (folio_total_mapcount, folio_referenced_one, rmap_walk_file, invalid_folio_referenced_vma, folio_unlock, rmap_walk_anon, folio_lock_anon_vma_read)
folio_referenced_one -> (folio_test_hugetlb, _raw_spin_unlock, page_vma_mapped_walk, __mmu_notifier_clear_flush_young, mlock_folio, ptep_clear_flush_young, hugetlb_basepage_index)
hugepage_add_anon_rmap -> (linear_hugepage_index)
hugepage_add_new_anon_rmap -> (linear_hugepage_index)
page_add_anon_rmap -> (linear_hugepage_index, mlock_folio, __mod_node_page_state)
page_add_file_rmap -> (mlock_folio, __mod_node_page_state)
page_address_in_vma -> (PageHuge, folio_anon_vma, hugetlb_basepage_index)
page_mkclean_one -> (folio_test_hugetlb, page_vma_mkclean_one, hugetlb_basepage_index)
page_remove_rmap -> (folio_test_hugetlb, __mod_node_page_state, munlock_folio)
page_vma_mkclean_one -> (__mmu_notifier_invalidate_range_start, __SCT__might_resched, ptep_clear_flush, page_vma_mapped_walk, __mmu_notifier_invalidate_range_end)
perf_trace_migration_pte -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_mm_migrate_pages -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_mm_migrate_pages_start -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_tlb_flush -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
pfn_mkclean_range -> (page_vma_mkclean_one)
rmap_walk -> (rmap_walk_anon, rmap_walk_file)
rmap_walk_anon -> (folio_test_hugetlb, down_read, up_read, anon_vma_interval_tree_iter_next, __SCT__cond_resched, down_read_trylock, PageHuge, folio_anon_vma, hugetlb_basepage_index, anon_vma_interval_tree_iter_first)
rmap_walk_file -> (vma_interval_tree_iter_first, folio_test_hugetlb, down_read, up_read, folio_mapping, __SCT__cond_resched, down_read_trylock, PageHuge, vma_interval_tree_iter_next, hugetlb_basepage_index)
rmap_walk_locked -> (rmap_walk_anon, rmap_walk_file)
trace_event_raw_event_migration_pte -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_mm_migrate_pages -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_mm_migrate_pages_start -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_tlb_flush -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_raw_output_migration_pte -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_mm_migrate_pages -> (trace_print_symbols_seq, trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_mm_migrate_pages_start -> (trace_print_symbols_seq, trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_tlb_flush -> (trace_print_symbols_seq, trace_handle_return, trace_raw_output_prep, trace_event_printf)
try_to_migrate -> (try_to_migrate_one, rmap_walk_file, rmap_walk_anon, folio_not_mapped, invalid_migration_vma, folio_lock_anon_vma_read)
try_to_migrate_one -> (__SCT__might_resched, folio_test_hugetlb, mlock_drain_local, huge_pmd_unshare, flush_tlb_mm_range, page_vma_mapped_walk, hugetlb_vma_trylock_write, hugetlb_basepage_index, __folio_put, _raw_spin_unlock, __mmu_notifier_invalidate_range_start, ptep_clear_flush, __traceiter_set_migration_pte, hugetlb_vma_unlock_write, adjust_range_if_pmd_sharing_possible, __mmu_notifier_invalidate_range_end, folio_mark_dirty, __probestub_set_migration_pte, page_remove_rmap, __SCT__tp_func_set_migration_pte, __mmu_notifier_invalidate_range)
try_to_unmap -> (try_to_unmap_one, rmap_walk_file, rmap_walk_anon, folio_not_mapped, folio_lock_anon_vma_read)
try_to_unmap_flush -> (arch_tlbbatch_flush)
try_to_unmap_flush_dirty -> (arch_tlbbatch_flush)
try_to_unmap_one -> (__SCT__might_resched, folio_test_hugetlb, mlock_drain_local, _raw_spin_lock, huge_pmd_unshare, flush_tlb_mm_range, page_vma_mapped_walk, hugetlb_vma_trylock_write, mlock_folio, hugetlb_basepage_index, __folio_put, _raw_spin_unlock, swap_free, __mmu_notifier_invalidate_range_start, ptep_clear_flush, hugetlb_vma_unlock_write, adjust_range_if_pmd_sharing_possible, __mmu_notifier_invalidate_range_end, mm_trace_rss_stat, percpu_counter_add_batch, folio_mark_dirty, folio_total_mapcount, page_remove_rmap, __mmu_notifier_invalidate_range, swap_duplicate)
unlink_anon_vmas -> (down_write, up_write, anon_vma_interval_tree_remove, kmem_cache_free, __put_anon_vma)
