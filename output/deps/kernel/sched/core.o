kernel/sched/core.o
__balance_push_cpu_stop -> (refcount_warn_saturate, _raw_spin_unlock, _raw_spin_lock, _raw_spin_lock_irq, select_fallback_rq, sched_clock_cpu, _raw_spin_unlock_irq, __migrate_task, __put_task_struct)
__cond_resched -> (__schedule)
__cond_resched_lock -> (_raw_spin_lock, _raw_spin_unlock, __SCT__cond_resched)
__cond_resched_rwlock_read -> (_raw_read_lock, _raw_read_unlock, __SCT__cond_resched)
__cond_resched_rwlock_write -> (_raw_write_lock, _raw_write_unlock, __SCT__cond_resched)
__do_sys_sched_yield -> (do_sched_yield)
__hrtick_start -> (_raw_spin_lock, hrtimer_start_range_ns, _raw_spin_unlock)
__ia32_sys_nice -> (capable, set_user_nice, security_task_setnice)
__ia32_sys_sched_getaffinity -> (_copy_to_user, sched_getaffinity)
__ia32_sys_sched_getattr -> (__se_sys_sched_getattr)
__ia32_sys_sched_getparam -> (__se_sys_sched_getparam)
__ia32_sys_sched_getscheduler -> (__rcu_read_unlock, security_task_getscheduler, __rcu_read_lock, find_task_by_vpid)
__ia32_sys_sched_rr_get_interval -> (sched_rr_get_interval, put_timespec64)
__ia32_sys_sched_rr_get_interval_time32 -> (put_old_timespec32, sched_rr_get_interval)
__ia32_sys_sched_setaffinity -> (sched_setaffinity, _copy_from_user)
__ia32_sys_sched_setattr -> (__se_sys_sched_setattr)
__ia32_sys_sched_setparam -> (do_sched_setscheduler)
__ia32_sys_sched_setscheduler -> (do_sched_setscheduler)
__migrate_task -> (move_queued_task, kthread_is_per_cpu)
__sched_dynamic_update -> (_printk, __SCT__might_resched, preempt_schedule_thunk, preempt_schedule_notrace_thunk, __SCT__preempt_schedule_notrace, __SCT__irqentry_exit_cond_resched, __SCT__cond_resched, __cond_resched, raw_irqentry_exit_cond_resched, __SCT__preempt_schedule, __static_call_return0, __static_call_update)
__sched_setaffinity -> (task_rq_lock, cpuset_cpus_allowed, __set_cpus_allowed_ptr_locked, __rcu_read_lock, __rcu_read_unlock)
__sched_setscheduler -> (__setparam_dl, pick_task_dl, rq_offline_dl, rq_online_fair, update_curr_rt, enqueue_task_fair, pick_next_task_rt, task_tick_fair, find_lock_later_rq, _raw_spin_rq_lock_irqsave, set_next_task_rt, pick_task_rt, yield_to_task_fair, select_task_rq_rt, switched_from_dl, update_curr_fair, dequeue_task_fair, check_preempt_curr_rt, prio_changed_dl, set_cpus_allowed_common, rq_offline_rt, switched_from_fair, put_prev_task_rt, __pick_next_task_fair, yield_task_fair, balance_fair, pick_task_fair, enqueue_task_rt, check_preempt_wakeup, balance_rt, migrate_task_rq_fair, balance_dl, task_rq_lock, put_prev_task_dl, sched_dl_overflow, select_task_rq_fair, cpuset_unlock, switched_to_rt, task_woken_dl, get_rr_interval_fair, find_lock_lowest_rq, task_tick_dl, switched_to_dl, rt_mutex_adjust_pi, prio_changed_fair, _raw_spin_unlock, set_next_task_fair, task_woken_rt, set_next_task_dl, yield_task_rt, migrate_task_rq_dl, put_prev_task_fair, prio_changed_rt, set_cpus_allowed_dl, task_dead_fair, switched_to_fair, __checkparam_dl, enqueue_task_dl, __rcu_read_lock, task_change_group_fair, balance_push, security_task_setscheduler, dl_param_changed, task_fork_fair, cpuset_lock, dequeue_task_rt, update_curr_dl, capable, __rcu_read_unlock, switched_from_rt, yield_task_dl, get_rr_interval_rt, rq_offline_fair, reweight_task, _raw_spin_unlock_irqrestore, task_tick_rt, dequeue_task_dl, select_task_rq_dl, task_fork_dl, check_preempt_curr_dl, sched_clock_cpu, rq_online_dl, rq_online_rt, pick_next_task_dl)
__schedule -> (_raw_spin_lock, __switch_to_asm, __traceiter_sched_switch, get_rr_interval_fair, check_preempt_wakeup, update_curr_idle, profile_hits, task_fork_fair, switched_to_idle, rq_online_fair, migrate_task_rq_fair, __schedule_bug, enqueue_task_fair, put_prev_task_idle, prio_changed_fair, task_tick_fair, finish_task_switch, enter_lazy_tlb, _raw_spin_unlock, set_next_task_fair, __perf_event_task_sched_out, switch_mm_irqs_off, __SCT__tp_func_sched_switch, yield_to_task_fair, prio_changed_idle, update_curr_fair, pick_task_idle, dequeue_task_fair, put_prev_task_fair, set_next_task_idle, balance_idle, dequeue_task_idle, set_cpus_allowed_common, rq_offline_fair, task_dead_fair, switched_to_fair, __delayacct_blkio_start, select_task_rq_fair, switched_from_fair, __pick_next_task_fair, pick_next_task_idle, task_tick_idle, yield_task_fair, ___perf_sw_event, mm_cid_get, __do_set_cpus_allowed, __probestub_sched_switch, sched_clock_cpu, balance_fair, select_task_rq_idle, task_change_group_fair, check_preempt_curr_idle, pick_next_task_fair, rcu_note_context_switch, pick_task_fair)
__schedule_bug -> (_printk, add_taint, check_panic_on_warn, dump_stack)
__se_sys_sched_getattr -> (security_task_getscheduler, find_task_by_vpid, __getparam_dl, __rcu_read_lock, __rcu_read_unlock, _copy_to_user)
__se_sys_sched_getparam -> (security_task_getscheduler, find_task_by_vpid, __rcu_read_lock, __rcu_read_unlock, _copy_to_user)
__se_sys_sched_setattr -> (refcount_warn_saturate, _copy_from_user, __sched_setscheduler, find_task_by_vpid, __getparam_dl, __rcu_read_lock, __put_task_struct, check_zeroed_user, __rcu_read_unlock)
__set_cpus_allowed_ptr_locked -> (__SCT__might_resched, refcount_warn_saturate, schedule, push_cpu_stop, _raw_spin_unlock, prepare_to_wait_event, cpumask_any_and_distribute, wake_up_var, __var_waitqueue, init_wait_var_entry, migration_cpu_stop, move_queued_task, _raw_spin_unlock_irqrestore, __init_swait_queue_head, complete_all, wait_for_completion, finish_wait, sched_clock_cpu, stop_one_cpu_nowait)
__task_rq_lock -> (_raw_spin_lock, _raw_spin_unlock)
__traceiter_ipi_entry -> (__SCT__tp_func_ipi_entry, __traceiter_ipi_entry, __probestub_ipi_entry)
__traceiter_ipi_exit -> (__SCT__tp_func_ipi_exit, __probestub_ipi_exit, __traceiter_ipi_exit)
__traceiter_ipi_raise -> (__probestub_ipi_raise, __SCT__tp_func_ipi_raise, __traceiter_ipi_raise)
__traceiter_ipi_send_cpu -> (__SCT__tp_func_ipi_send_cpu, __probestub_ipi_send_cpu, __traceiter_ipi_send_cpu)
__traceiter_ipi_send_cpumask -> (__probestub_ipi_send_cpumask, __SCT__tp_func_ipi_send_cpumask, __traceiter_ipi_send_cpumask)
__traceiter_pelt_cfs_tp -> (__probestub_pelt_cfs_tp, __traceiter_pelt_cfs_tp, __SCT__tp_func_pelt_cfs_tp)
__traceiter_pelt_dl_tp -> (__probestub_pelt_dl_tp, __traceiter_pelt_dl_tp, __SCT__tp_func_pelt_dl_tp)
__traceiter_pelt_irq_tp -> (__SCT__tp_func_pelt_irq_tp, __probestub_pelt_irq_tp, __traceiter_pelt_irq_tp)
__traceiter_pelt_rt_tp -> (__traceiter_pelt_rt_tp, __SCT__tp_func_pelt_rt_tp, __probestub_pelt_rt_tp)
__traceiter_pelt_se_tp -> (__traceiter_pelt_se_tp, __SCT__tp_func_pelt_se_tp, __probestub_pelt_se_tp)
__traceiter_pelt_thermal_tp -> (__probestub_pelt_thermal_tp, __traceiter_pelt_thermal_tp, __SCT__tp_func_pelt_thermal_tp)
__traceiter_sched_cpu_capacity_tp -> (__traceiter_sched_cpu_capacity_tp, __probestub_sched_cpu_capacity_tp, __SCT__tp_func_sched_cpu_capacity_tp)
__traceiter_sched_kthread_stop -> (__traceiter_sched_kthread_stop, __SCT__tp_func_sched_kthread_stop, __probestub_sched_kthread_stop)
__traceiter_sched_kthread_stop_ret -> (__SCT__tp_func_sched_kthread_stop_ret, __probestub_sched_kthread_stop_ret, __traceiter_sched_kthread_stop_ret)
__traceiter_sched_kthread_work_execute_end -> (__probestub_sched_kthread_work_execute_end, __traceiter_sched_kthread_work_execute_end, __SCT__tp_func_sched_kthread_work_execute_end)
__traceiter_sched_kthread_work_execute_start -> (__probestub_sched_kthread_work_execute_start, __traceiter_sched_kthread_work_execute_start, __SCT__tp_func_sched_kthread_work_execute_start)
__traceiter_sched_kthread_work_queue_work -> (__traceiter_sched_kthread_work_queue_work, __probestub_sched_kthread_work_queue_work, __SCT__tp_func_sched_kthread_work_queue_work)
__traceiter_sched_migrate_task -> (__probestub_sched_migrate_task, __traceiter_sched_migrate_task, __SCT__tp_func_sched_migrate_task)
__traceiter_sched_move_numa -> (__traceiter_sched_move_numa, __SCT__tp_func_sched_move_numa, __probestub_sched_move_numa)
__traceiter_sched_overutilized_tp -> (__traceiter_sched_overutilized_tp, __SCT__tp_func_sched_overutilized_tp, __probestub_sched_overutilized_tp)
__traceiter_sched_pi_setprio -> (__probestub_sched_pi_setprio, __traceiter_sched_pi_setprio, __SCT__tp_func_sched_pi_setprio)
__traceiter_sched_process_exec -> (__SCT__tp_func_sched_process_exec, __traceiter_sched_process_exec, __probestub_sched_process_exec)
__traceiter_sched_process_exit -> (__SCT__tp_func_sched_process_exit, __traceiter_sched_process_exit, __probestub_sched_process_exit)
__traceiter_sched_process_fork -> (__traceiter_sched_process_fork, __SCT__tp_func_sched_process_fork, __probestub_sched_process_fork)
__traceiter_sched_process_free -> (__SCT__tp_func_sched_process_free, __traceiter_sched_process_free, __probestub_sched_process_free)
__traceiter_sched_process_wait -> (__probestub_sched_process_wait, __SCT__tp_func_sched_process_wait, __traceiter_sched_process_wait)
__traceiter_sched_stat_blocked -> (__traceiter_sched_stat_blocked, __SCT__tp_func_sched_stat_blocked, __probestub_sched_stat_blocked)
__traceiter_sched_stat_iowait -> (__probestub_sched_stat_iowait, __SCT__tp_func_sched_stat_iowait, __traceiter_sched_stat_iowait)
__traceiter_sched_stat_runtime -> (__traceiter_sched_stat_runtime, __SCT__tp_func_sched_stat_runtime, __probestub_sched_stat_runtime)
__traceiter_sched_stat_sleep -> (__probestub_sched_stat_sleep, __traceiter_sched_stat_sleep, __SCT__tp_func_sched_stat_sleep)
__traceiter_sched_stat_wait -> (__probestub_sched_stat_wait, __traceiter_sched_stat_wait, __SCT__tp_func_sched_stat_wait)
__traceiter_sched_stick_numa -> (__traceiter_sched_stick_numa, __SCT__tp_func_sched_stick_numa, __probestub_sched_stick_numa)
__traceiter_sched_swap_numa -> (__probestub_sched_swap_numa, __traceiter_sched_swap_numa, __SCT__tp_func_sched_swap_numa)
__traceiter_sched_switch -> (__traceiter_sched_switch, __probestub_sched_switch, __SCT__tp_func_sched_switch)
__traceiter_sched_update_nr_running_tp -> (__traceiter_sched_update_nr_running_tp, __SCT__tp_func_sched_update_nr_running_tp, __probestub_sched_update_nr_running_tp)
__traceiter_sched_util_est_cfs_tp -> (__probestub_sched_util_est_cfs_tp, __traceiter_sched_util_est_cfs_tp, __SCT__tp_func_sched_util_est_cfs_tp)
__traceiter_sched_util_est_se_tp -> (__probestub_sched_util_est_se_tp, __traceiter_sched_util_est_se_tp, __SCT__tp_func_sched_util_est_se_tp)
__traceiter_sched_wait_task -> (__traceiter_sched_wait_task, __probestub_sched_wait_task, __SCT__tp_func_sched_wait_task)
__traceiter_sched_wake_idle_without_ipi -> (__traceiter_sched_wake_idle_without_ipi, __probestub_sched_wake_idle_without_ipi, __SCT__tp_func_sched_wake_idle_without_ipi)
__traceiter_sched_wakeup -> (__probestub_sched_wakeup, __SCT__tp_func_sched_wakeup, __traceiter_sched_wakeup)
__traceiter_sched_wakeup_new -> (__traceiter_sched_wakeup_new, __SCT__tp_func_sched_wakeup_new, __probestub_sched_wakeup_new)
__traceiter_sched_waking -> (__probestub_sched_waking, __SCT__tp_func_sched_waking, __traceiter_sched_waking)
__x64_sys_nice -> (capable, set_user_nice, security_task_setnice)
__x64_sys_sched_getaffinity -> (_copy_to_user, sched_getaffinity)
__x64_sys_sched_getattr -> (__se_sys_sched_getattr)
__x64_sys_sched_getparam -> (__se_sys_sched_getparam)
__x64_sys_sched_getscheduler -> (__rcu_read_unlock, security_task_getscheduler, __rcu_read_lock, find_task_by_vpid)
__x64_sys_sched_rr_get_interval -> (sched_rr_get_interval, put_timespec64)
__x64_sys_sched_rr_get_interval_time32 -> (put_old_timespec32, sched_rr_get_interval)
__x64_sys_sched_setaffinity -> (sched_setaffinity, _copy_from_user)
__x64_sys_sched_setattr -> (__se_sys_sched_setattr)
__x64_sys_sched_setparam -> (do_sched_setscheduler)
__x64_sys_sched_setscheduler -> (do_sched_setscheduler)
_raw_spin_rq_lock_irqsave -> (_raw_spin_lock)
activate_task -> (sched_mm_cid_migrate_to, sched_clock_cpu)
balance_push -> (__balance_push_cpu_stop, refcount_warn_saturate, _raw_spin_unlock, _raw_spin_lock, rcuwait_wake_up, stop_one_cpu_nowait, balance_push, kthread_is_per_cpu)
call_function_single_prep_ipi -> (__traceiter_sched_wake_idle_without_ipi, __probestub_sched_wake_idle_without_ipi, __SCT__tp_func_sched_wake_idle_without_ipi)
call_trace_sched_update_nr_running -> (__traceiter_sched_update_nr_running_tp, __SCT__tp_func_sched_update_nr_running_tp, __probestub_sched_update_nr_running_tp)
can_nice -> (capable)
check_preempt_curr -> (resched_curr)
cpu_cgroup_attach -> (cgroup_taskset_next, sched_move_task, cgroup_taskset_first)
cpu_cgroup_css_alloc -> (sched_create_group)
cpu_cgroup_css_free -> (unregister_fair_sched_group, unregister_rt_sched_group, call_rcu, sched_free_group_rcu)
cpu_cgroup_css_online -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, online_fair_sched_group)
cpu_cgroup_css_released -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore)
cpu_idle_write_s64 -> (sched_group_set_idle)
cpu_shares_write_u64 -> (sched_group_set_shares)
cpu_weight_nice_write_s64 -> (sched_group_set_shares)
cpu_weight_write_u64 -> (sched_group_set_shares)
cpuset_cpumask_can_shrink -> (dl_cpuset_cpumask_can_shrink)
deactivate_task -> (sched_clock_cpu)
default_wake_function -> (try_to_wake_up)
dl_task_check_affinity -> (__rcu_read_unlock, __rcu_read_lock)
do_sched_setscheduler -> (refcount_warn_saturate, _copy_from_user, __sched_setscheduler, find_task_by_vpid, __rcu_read_lock, __put_task_struct, __rcu_read_unlock)
do_sched_yield -> (_raw_spin_lock, schedule, _raw_spin_unlock)
do_set_cpus_allowed -> (kvfree_call_rcu)
do_task_dead -> (__schedule, _raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore)
double_rq_lock -> (_raw_spin_lock)
dump_cpu_task -> (show_regs, arch_trigger_cpumask_backtrace)
dup_user_cpus_ptr -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, kmalloc_node_trace, kfree)
finish_task_switch -> (__perf_event_task_sched_in, _raw_spin_unlock, ___perf_sw_event, __warn_printk, put_task_stack, __mmdrop, put_task_struct_rcu_user)
force_compatible_cpus_allowed_ptr -> (__printk_ratelimit, cpus_read_unlock, _raw_spin_unlock, task_rq_lock, _printk_deferred, __set_cpus_allowed_ptr_locked, cpuset_cpus_allowed, _raw_spin_unlock_irqrestore, cpus_read_lock)
force_schedstat_enabled -> (_printk, static_key_enable)
get_nohz_timer_target -> (housekeeping_test_cpu, __rcu_read_lock, __rcu_read_unlock, housekeeping_any_cpu, housekeeping_cpumask)
get_wchan -> (_raw_spin_lock_irq, __get_wchan, _raw_spin_unlock_irq)
hrtick -> (_raw_spin_lock, sched_clock_cpu, _raw_spin_unlock)
hrtick_start -> (hrtimer_start_range_ns, smp_call_function_single_async)
idle_task_exit -> (switch_mm)
in_sched_functions -> (in_lock_functions)
init_idle -> (__dl_clear_params, kthread_set_per_cpu, task_mm_cid_work, _raw_spin_lock, update_curr_idle, switched_to_idle, sprintf, put_prev_task_idle, init_dl_inactive_task_timer, _raw_spin_unlock, _raw_spin_lock_irqsave, init_dl_task_timer, __rcu_read_unlock, prio_changed_idle, pick_task_idle, set_next_task_idle, set_task_rq_fair, balance_idle, dequeue_task_idle, set_cpus_allowed_common, sched_clock, _raw_spin_unlock_irqrestore, task_tick_idle, pick_next_task_idle, select_task_rq_idle, __rcu_read_lock, check_preempt_curr_idle)
init_sched_mm_cid -> (task_mm_cid_work)
io_schedule -> (schedule, __blk_flush_plug)
io_schedule_prepare -> (__blk_flush_plug)
io_schedule_timeout -> (__blk_flush_plug, schedule_timeout)
kick_process -> (kvm_smp_send_call_func_ipi, native_send_call_func_ipi, native_smp_prepare_cpus, resume_play_dead, native_kick_ap, vmware_smp_prepare_boot_cpu, native_smp_cpus_done, kdump_nmi_shootdown_cpus, native_cpu_disable, native_smp_prepare_boot_cpu, __SCT__tp_func_ipi_send_cpu, __traceiter_ipi_send_cpu, native_send_call_func_single_ipi, native_stop_other_cpus, __probestub_ipi_send_cpu, kvm_smp_prepare_boot_cpu, native_play_dead, native_smp_send_reschedule)
klp_cond_resched -> (__schedule)
migrate_enable -> (task_rq_lock, __set_cpus_allowed_ptr_locked)
migration_cpu_stop -> (_raw_spin_unlock, _raw_spin_lock, migration_cpu_stop, sched_clock_cpu, __migrate_task, flush_smp_call_function_queue, _raw_spin_unlock_irqrestore, complete_all, stop_one_cpu_nowait)
migration_init -> (update_max_interval)
mm_cid_get -> (_raw_spin_lock, _raw_spin_unlock)
move_queued_task -> (_raw_spin_unlock, _raw_spin_lock, set_task_cpu, resched_curr, activate_task)
nohz_csd_func -> (raise_softirq_irqoff)
normalize_rt_tasks -> (do_no_restart_syscall, __sched_setscheduler, _raw_read_unlock, set_user_nice, _raw_read_lock)
perf_trace_ipi_handler -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_ipi_raise -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_ipi_send_cpu -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_ipi_send_cpumask -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_kthread_stop -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_kthread_stop_ret -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_kthread_work_execute_end -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_kthread_work_execute_start -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_kthread_work_queue_work -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_migrate_task -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_move_numa -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_numa_pair_template -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_pi_setprio -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_process_exec -> (strcpy, strlen, perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_process_fork -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_process_template -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_process_wait -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_stat_runtime -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_stat_template -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_switch -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_wake_idle_without_ipi -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
perf_trace_sched_wakeup_template -> (perf_trace_buf_alloc, perf_trace_run_bpf_submit)
preempt_dynamic_init -> (mutex_unlock, mutex_lock, __sched_dynamic_update)
preempt_schedule -> (preempt_schedule_common)
preempt_schedule_common -> (__schedule)
preempt_schedule_irq -> (__schedule)
preempt_schedule_notrace -> (__schedule)
push_cpu_stop -> (refcount_warn_saturate, _raw_spin_unlock, _raw_spin_lock, _raw_spin_lock_irq, set_task_cpu, resched_curr, activate_task, _raw_spin_unlock_irq, __put_task_struct, deactivate_task)
raw_spin_rq_lock_nested -> (_raw_spin_lock)
raw_spin_rq_trylock -> (_raw_spin_trylock)
raw_spin_rq_unlock -> (_raw_spin_unlock)
relax_compatible_cpus_allowed_ptr -> (__sched_setaffinity)
release_user_cpus_ptr -> (kfree)
resched_cpu -> (_raw_spin_lock, resched_curr, _raw_spin_unlock)
resched_curr -> (__traceiter_sched_wake_idle_without_ipi, native_smp_prepare_cpus, resume_play_dead, native_kick_ap, __SCT__tp_func_sched_wake_idle_without_ipi, native_play_dead, native_smp_send_reschedule, native_cpu_disable, native_smp_prepare_boot_cpu, native_send_call_func_single_ipi, native_stop_other_cpus, kvm_smp_prepare_boot_cpu, __probestub_ipi_send_cpu, kvm_smp_send_call_func_ipi, native_send_call_func_ipi, __probestub_sched_wake_idle_without_ipi, vmware_smp_prepare_boot_cpu, native_smp_cpus_done, kdump_nmi_shootdown_cpus, __SCT__tp_func_ipi_send_cpu, __traceiter_ipi_send_cpu)
rt_mutex_setprio -> (pick_task_dl, __probestub_sched_pi_setprio, _raw_spin_lock, enqueue_task_rt, get_rr_interval_fair, check_preempt_wakeup, rq_offline_dl, balance_rt, task_fork_fair, rq_online_fair, find_lock_lowest_rq, migrate_task_rq_fair, task_tick_dl, update_curr_rt, switched_to_dl, enqueue_task_fair, pick_next_task_rt, balance_dl, prio_changed_fair, task_tick_fair, _raw_spin_unlock, find_lock_later_rq, set_next_task_fair, dequeue_task_rt, put_prev_task_dl, set_next_task_rt, pick_task_rt, task_woken_rt, update_curr_dl, set_next_task_dl, yield_task_rt, yield_to_task_fair, select_task_rq_rt, __SCT__tp_func_sched_pi_setprio, switched_from_dl, switched_from_rt, migrate_task_rq_dl, update_curr_fair, check_preempt_curr_rt, dequeue_task_fair, put_prev_task_fair, prio_changed_rt, __traceiter_sched_pi_setprio, yield_task_dl, prio_changed_dl, set_cpus_allowed_dl, get_rr_interval_rt, set_cpus_allowed_common, rq_offline_fair, task_dead_fair, switched_to_fair, select_task_rq_fair, task_tick_rt, rq_offline_rt, switched_from_fair, enqueue_task_dl, dequeue_task_dl, put_prev_task_rt, switched_to_rt, __pick_next_task_fair, select_task_rq_dl, task_fork_dl, yield_task_fair, check_preempt_curr_dl, task_woken_dl, sched_clock_cpu, rq_online_dl, balance_fair, rq_online_rt, pick_next_task_dl, task_change_group_fair, pick_task_fair)
sched_cgroup_fork -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, set_task_rq_fair)
sched_core_sysctl_init -> (__register_sysctl_init, sysctl_schedstats)
sched_cpu_activate -> (partition_sched_domains, _raw_spin_unlock, _raw_spin_lock, cpuset_update_active_cpus, sched_domains_numa_masks_set, static_key_slow_inc_cpuslocked, sched_update_numa, balance_push, cpuset_force_rebuild)
sched_cpu_deactivate -> (partition_sched_domains, _raw_spin_unlock, synchronize_rcu, _raw_spin_lock, dl_bw_check_overflow, cpuset_update_active_cpus, static_key_slow_dec_cpuslocked, nohz_balance_exit_idle, sched_domains_numa_masks_clear, sched_update_numa, set_rq_offline, balance_push)
sched_cpu_dying -> (_printk, update_max_interval, hrtimer_cancel, do_no_restart_syscall, _raw_spin_unlock, _raw_spin_lock, __warn_printk, calc_load_fold_active, hrtimer_active)
sched_cpu_starting -> (update_max_interval)
sched_cpu_util -> (cpu_util_cfs)
sched_cpu_wait_empty -> (finish_rcuwait, schedule)
sched_create_group -> (kmem_cache_alloc, kmem_cache_free, alloc_rt_sched_group, alloc_fair_sched_group, free_fair_sched_group, free_rt_sched_group)
sched_destroy_group -> (sched_unregister_group_rcu, call_rcu)
sched_dynamic_klp_disable -> (mutex_unlock, mutex_lock, __sched_dynamic_update)
sched_dynamic_klp_enable -> (klp_cond_resched, mutex_lock, mutex_unlock, __SCT__cond_resched, __static_call_return0, __static_call_update)
sched_dynamic_mode -> (strcmp)
sched_dynamic_update -> (mutex_unlock, mutex_lock, __sched_dynamic_update)
sched_exec -> (migration_cpu_stop, _raw_spin_lock_irqsave, stop_one_cpu, _raw_spin_unlock_irqrestore)
sched_fork -> (__dl_clear_params, task_mm_cid_work, enqueue_task_rt, get_rr_interval_fair, check_preempt_wakeup, balance_rt, task_fork_fair, rq_online_fair, find_lock_lowest_rq, migrate_task_rq_fair, update_curr_rt, enqueue_task_fair, pick_next_task_rt, prio_changed_fair, task_tick_fair, init_dl_inactive_task_timer, set_next_task_fair, dequeue_task_rt, set_next_task_rt, pick_task_rt, task_woken_rt, yield_to_task_fair, init_dl_task_timer, yield_task_rt, select_task_rq_rt, switched_from_rt, update_curr_fair, dequeue_task_fair, check_preempt_curr_rt, put_prev_task_fair, prio_changed_rt, get_rr_interval_rt, set_cpus_allowed_common, rq_offline_fair, task_dead_fair, switched_to_fair, select_task_rq_fair, task_tick_rt, rq_offline_rt, switched_from_fair, put_prev_task_rt, switched_to_rt, __pick_next_task_fair, yield_task_fair, init_entity_runnable_average, balance_fair, rq_online_rt, task_change_group_fair, pick_task_fair)
sched_free_group_rcu -> (free_rt_sched_group, kmem_cache_free, free_fair_sched_group)
sched_getaffinity -> (security_task_getscheduler, find_task_by_vpid, _raw_spin_lock_irqsave, __rcu_read_lock, _raw_spin_unlock_irqrestore, __rcu_read_unlock)
sched_init -> (init_dl_rq, pick_task_dl, _raw_spin_lock, init_rt_rq, update_curr_idle, rq_offline_dl, wait_bit_init, set_next_task_stop, rq_online_fair, update_curr_rt, enqueue_task_fair, enqueue_task_stop, pick_next_task_rt, task_tick_fair, do_no_restart_syscall, enter_lazy_tlb, find_lock_later_rq, set_next_task_rt, pick_task_rt, yield_to_task_fair, select_task_rq_rt, init_rt_bandwidth, switched_from_dl, update_curr_fair, pick_task_idle, dequeue_task_fair, check_preempt_curr_rt, balance_idle, set_cpus_allowed_common, prio_changed_dl, switched_to_stop, rq_offline_rt, switched_from_fair, put_prev_task_rt, __pick_next_task_fair, task_tick_idle, pick_next_task_idle, yield_task_fair, balance_fair, check_preempt_curr_idle, pick_task_fair, enqueue_task_rt, check_preempt_wakeup, balance_rt, migrate_task_rq_fair, task_tick_stop, balance_dl, init_tg_cfs_entry, init_sched_fair_class, put_prev_task_dl, prio_changed_idle, init_defrootdomain, put_prev_task_stop, prio_changed_stop, hrtick, select_task_rq_fair, hrtimer_init, switched_to_rt, update_curr_stop, task_woken_dl, init_idle, idle_thread_set_boot_cpu, pick_next_task_stop, pick_task_stop, get_rr_interval_fair, preempt_dynamic_init, find_lock_lowest_rq, __hrtick_start, init_cfs_rq, task_tick_dl, switched_to_dl, put_prev_task_idle, prio_changed_fair, _raw_spin_unlock, set_next_task_fair, task_woken_rt, set_next_task_dl, yield_task_rt, migrate_task_rq_dl, put_prev_task_fair, prio_changed_rt, dequeue_task_idle, set_cpus_allowed_dl, task_dead_fair, switched_to_fair, enqueue_task_dl, __kmalloc, select_task_rq_stop, select_task_rq_idle, task_change_group_fair, balance_push, check_preempt_curr_stop, task_fork_fair, switched_to_idle, rq_attach_root, set_kthread_struct, kmem_cache_create, nohz_csd_func, dequeue_task_rt, update_curr_dl, balance_stop, yield_task_stop, switched_from_rt, set_next_task_idle, yield_task_dl, get_rr_interval_rt, rq_offline_fair, task_tick_rt, dequeue_task_dl, select_task_rq_dl, task_fork_dl, dequeue_task_stop, check_preempt_curr_dl, rq_online_dl, init_cfs_bandwidth, rq_online_rt, pick_next_task_dl)
sched_init_smp -> (mutex_lock, mutex_unlock, sched_init_granularity, sched_init_domains, set_cpus_allowed_ptr, init_sched_dl_class, sched_init_numa, init_sched_rt_class, housekeeping_cpumask)
sched_mm_cid_after_execve -> (_raw_spin_lock, mm_cid_get, _raw_spin_unlock)
sched_mm_cid_before_execve -> (_raw_spin_lock, _raw_spin_unlock)
sched_mm_cid_exit_signals -> (_raw_spin_lock, _raw_spin_unlock)
sched_mm_cid_migrate_to -> (__rcu_read_unlock, __rcu_read_lock)
sched_mm_cid_remote_clear -> (__rcu_read_unlock, __rcu_read_lock)
sched_move_task -> (_raw_spin_unlock, task_rq_lock, set_task_rq_fair, resched_curr, sched_clock_cpu, _raw_spin_unlock_irqrestore)
sched_online_group -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, online_fair_sched_group)
sched_release_group -> (_raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore)
sched_rr_get_interval -> (security_task_getscheduler, find_task_by_vpid, _raw_spin_unlock, task_rq_lock, __rcu_read_lock, _raw_spin_unlock_irqrestore, jiffies_to_timespec64, __rcu_read_unlock)
sched_set_fifo -> (__sched_setscheduler)
sched_set_fifo_low -> (__sched_setscheduler)
sched_set_normal -> (__sched_setscheduler)
sched_set_stop_task -> (pick_task_stop, check_preempt_curr_stop, enqueue_task_rt, set_next_task_stop, balance_rt, find_lock_lowest_rq, update_curr_rt, enqueue_task_stop, pick_next_task_rt, task_tick_stop, dequeue_task_rt, set_next_task_rt, pick_task_rt, task_woken_rt, yield_task_rt, select_task_rq_rt, balance_stop, switched_from_rt, yield_task_stop, put_prev_task_stop, check_preempt_curr_rt, __sched_setscheduler, prio_changed_rt, prio_changed_stop, get_rr_interval_rt, set_cpus_allowed_common, switched_to_stop, task_tick_rt, rq_offline_rt, put_prev_task_rt, switched_to_rt, select_task_rq_stop, update_curr_stop, dequeue_task_stop, rq_online_rt, pick_next_task_stop)
sched_setaffinity -> (__sched_setaffinity, refcount_warn_saturate, find_task_by_vpid, security_task_setscheduler, ns_capable, __rcu_read_lock, __put_task_struct, __rcu_read_unlock, kfree, kmalloc_node_trace)
sched_setattr -> (__sched_setscheduler)
sched_setattr_nocheck -> (__sched_setscheduler)
sched_setscheduler -> (__sched_setscheduler)
sched_setscheduler_nocheck -> (__sched_setscheduler)
sched_show_task -> (print_stop_info, _printk, refcount_warn_saturate, show_stack, put_task_stack, __rcu_read_lock, __rcu_read_unlock, print_worker_info)
sched_ttwu_pending -> (ttwu_do_activate, _raw_spin_unlock, _raw_spin_lock, set_task_cpu, sched_clock_cpu)
sched_unregister_group_rcu -> (unregister_fair_sched_group, unregister_rt_sched_group, call_rcu, sched_free_group_rcu)
schedule -> (__schedule, __blk_flush_plug, wq_worker_running, io_wq_worker_sleeping, io_wq_worker_running, wq_worker_sleeping)
schedule_idle -> (__schedule)
schedule_preempt_disabled -> (schedule)
schedule_tail -> (calculate_sigpending, finish_task_switch, __task_pid_nr_ns)
scheduler_tick -> (calc_global_load_tick, wq_worker_tick, task_work_add, _raw_spin_unlock, perf_event_task_tick, _raw_spin_lock, sched_clock_cpu, housekeeping_test_cpu, arch_scale_freq_tick, trigger_load_balance, sched_clock_tick)
select_fallback_rq -> (__printk_ratelimit, cpuset_cpus_allowed_fallback, do_set_cpus_allowed, _printk_deferred, kthread_is_per_cpu)
set_cpus_allowed_ptr -> (task_rq_lock, __set_cpus_allowed_ptr_locked)
set_rq_offline -> (sched_clock_cpu)
set_task_cpu -> (__probestub_sched_migrate_task, __traceiter_sched_migrate_task, set_task_rq_fair, __SCT__tp_func_sched_migrate_task)
set_user_nice -> (get_rr_interval_fair, check_preempt_wakeup, task_fork_fair, rq_online_fair, migrate_task_rq_fair, enqueue_task_fair, prio_changed_fair, task_tick_fair, _raw_spin_unlock, task_rq_lock, set_next_task_fair, yield_to_task_fair, update_curr_fair, dequeue_task_fair, put_prev_task_fair, set_cpus_allowed_common, rq_offline_fair, reweight_task, task_dead_fair, switched_to_fair, _raw_spin_unlock_irqrestore, select_task_rq_fair, switched_from_fair, __pick_next_task_fair, yield_task_fair, sched_clock_cpu, balance_fair, task_change_group_fair, pick_task_fair)
setup_preempt_mode -> (_printk, mutex_lock, __sched_dynamic_update, mutex_unlock, sched_dynamic_mode)
setup_schedstats -> (_printk, static_key_enable, static_key_disable, strcmp)
show_state_filter -> (__rcu_read_unlock, do_no_restart_syscall, __rcu_read_lock, sched_show_task)
sysctl_schedstats -> (capable, proc_dointvec_minmax, static_key_disable, static_key_enable)
task_call_func -> (_raw_spin_lock, _raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, _raw_spin_unlock)
task_mm_cid_work -> (__rcu_read_unlock, sched_mm_cid_remote_clear, __rcu_read_lock)
task_rq_lock -> (_raw_spin_lock, _raw_spin_lock_irqsave, _raw_spin_unlock_irqrestore, _raw_spin_unlock)
task_sched_runtime -> (task_rq_lock, _raw_spin_unlock_irqrestore, sched_clock_cpu, _raw_spin_unlock)
task_tick_mm_cid -> (task_work_add)
trace_event_raw_event_ipi_handler -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_ipi_raise -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_ipi_send_cpu -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_ipi_send_cpumask -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_kthread_stop -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_kthread_stop_ret -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_kthread_work_execute_end -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_kthread_work_execute_start -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_kthread_work_queue_work -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_migrate_task -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_move_numa -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_numa_pair_template -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_pi_setprio -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_process_exec -> (strlen, trace_event_buffer_commit, trace_event_buffer_reserve, strcpy, __trace_trigger_soft_disabled)
trace_event_raw_event_sched_process_fork -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_process_template -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_process_wait -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_stat_runtime -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_stat_template -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_switch -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_wake_idle_without_ipi -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_event_raw_event_sched_wakeup_template -> (trace_event_buffer_reserve, __trace_trigger_soft_disabled, trace_event_buffer_commit)
trace_raw_output_ipi_handler -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_ipi_raise -> (trace_handle_return, trace_raw_output_prep, trace_print_bitmask_seq, trace_event_printf)
trace_raw_output_ipi_send_cpu -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_ipi_send_cpumask -> (trace_handle_return, trace_raw_output_prep, trace_print_bitmask_seq, trace_event_printf)
trace_raw_output_sched_kthread_stop -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_kthread_stop_ret -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_kthread_work_execute_end -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_kthread_work_execute_start -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_kthread_work_queue_work -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_migrate_task -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_move_numa -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_numa_pair_template -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_pi_setprio -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_process_exec -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_process_fork -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_process_template -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_process_wait -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_stat_runtime -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_stat_template -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_switch -> (trace_handle_return, trace_print_flags_seq, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_wake_idle_without_ipi -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
trace_raw_output_sched_wakeup_template -> (trace_handle_return, trace_raw_output_prep, trace_event_printf)
try_to_wake_up -> (_raw_spin_lock, __SCT__tp_func_sched_wakeup, __traceiter_sched_waking, __probestub_sched_waking, _raw_spin_unlock, _raw_spin_lock_irqsave, __SCT__tp_func_sched_waking, __rcu_read_unlock, ttwu_queue_wakelist, set_task_cpu, resched_curr, __traceiter_sched_wakeup, __delayacct_blkio_end, _raw_spin_unlock_irqrestore, __probestub_sched_wakeup, ttwu_do_activate, select_fallback_rq, sched_clock_cpu, __rcu_read_lock, kthread_is_per_cpu)
ttwu_do_activate -> (resched_curr, __traceiter_sched_wakeup, activate_task, __delayacct_blkio_end, __SCT__tp_func_sched_wakeup, __probestub_sched_wakeup)
ttwu_queue_wakelist -> (__smp_call_single_queue, sched_clock_cpu)
update_rq_clock -> (sched_clock_cpu)
wait_task_inactive -> (schedule_hrtimeout, _raw_spin_unlock, __traceiter_sched_wait_task, task_rq_lock, __probestub_sched_wait_task, _raw_spin_unlock_irqrestore, __SCT__tp_func_sched_wait_task)
wake_q_add -> (refcount_warn_saturate)
wake_q_add_safe -> (refcount_warn_saturate, __put_task_struct)
wake_up_if_idle -> (_raw_spin_unlock, _raw_spin_lock, resched_curr, __rcu_read_lock, __rcu_read_unlock)
wake_up_new_task -> (_raw_spin_unlock, _raw_spin_lock, _raw_spin_lock_irqsave, resched_curr, __traceiter_sched_wakeup_new, __SCT__tp_func_sched_wakeup_new, __probestub_sched_wakeup_new, activate_task, sched_clock_cpu, select_fallback_rq, post_init_entity_util_avg, set_task_rq_fair, _raw_spin_unlock_irqrestore, kthread_is_per_cpu)
wake_up_nohz_cpu -> (__traceiter_sched_wake_idle_without_ipi, native_smp_prepare_cpus, resume_play_dead, native_kick_ap, __SCT__tp_func_sched_wake_idle_without_ipi, native_play_dead, native_smp_send_reschedule, native_cpu_disable, native_smp_prepare_boot_cpu, native_send_call_func_single_ipi, native_stop_other_cpus, kvm_smp_prepare_boot_cpu, __probestub_ipi_send_cpu, kvm_smp_send_call_func_ipi, native_send_call_func_ipi, __probestub_sched_wake_idle_without_ipi, vmware_smp_prepare_boot_cpu, native_smp_cpus_done, kdump_nmi_shootdown_cpus, __SCT__tp_func_ipi_send_cpu, __traceiter_ipi_send_cpu)
wake_up_process -> (try_to_wake_up)
wake_up_q -> (refcount_warn_saturate, try_to_wake_up, __put_task_struct)
wake_up_state -> (try_to_wake_up)
yield -> (do_sched_yield)
yield_to -> (_raw_spin_lock, schedule, resched_curr, _raw_spin_unlock)
